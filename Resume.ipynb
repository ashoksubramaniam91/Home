{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resume-Aprajita Srivastava.pdf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>E-mail</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>Masters</th>\n",
       "      <th>Projects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Resume-Aprajita Srivastava.pdf</td>\n",
       "      <td>919668008450</td>\n",
       "      <td>aprajita.srivastava1112@gmail.com</td>\n",
       "      <td>({excel, logistic regression, r, data science,...</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>0</td>\n",
       "      <td>Projects   Project: Prepaid Installment Billin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name         Phone  \\\n",
       "0  Resume-Aprajita Srivastava.pdf  919668008450   \n",
       "\n",
       "                              E-mail  \\\n",
       "0  aprajita.srivastava1112@gmail.com   \n",
       "\n",
       "                                              Skills Bachelors  Masters  \\\n",
       "0  ({excel, logistic regression, r, data science,...    B.Tech        0   \n",
       "\n",
       "                                            Projects  \n",
       "0  Projects   Project: Prepaid Installment Billin...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "import sys\n",
    "#reload(sys)\n",
    "import pandas as pd\n",
    "#sys.setdefaultencoding('utf8')\n",
    "#from cStringIO import StringIO\n",
    "from io import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import os\n",
    "import sys, getopt\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "#Function converting pdf to string\n",
    "def convert(fname, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "\n",
    "    infile = open(fname, 'rb')\n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        interpreter.process_page(page)\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close\n",
    "    return text\n",
    "\n",
    "def phone(str1):\n",
    "    if re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{12}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{12}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{10}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE)\n",
    "    \n",
    "def extract_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(string)\n",
    "\n",
    "\n",
    "filename='C:/Users/ashok.s/Downloads/Resume-Aprajita Srivastava.pdf'\n",
    "\n",
    "resume_string = convert(filename)\n",
    "str1= resume_string.replace(' ', ' ').replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "import os\n",
    "base=os.path.basename(filename)    \n",
    "name=base.split('_')\n",
    "print(name)\n",
    "\n",
    "phone=phone(str1)\n",
    "\n",
    "email=extract_email_addresses(str1)\n",
    "\n",
    "l1=['PCA',\n",
    " 'dimension reduction',\n",
    " 'Python',\n",
    " 'PCA',\n",
    " 'Logistic Regression',\n",
    " 'Decision Tree',\n",
    " 'Random Forest',\n",
    " 'NaÃ¯ve Baye',\n",
    " 'Regression testing',\n",
    " 'analysis /  reporting',\n",
    " 'sql',\n",
    " 'statistics',\n",
    " 'EDA',\n",
    " 'Tableau',\n",
    " 'Data cleaning',\n",
    " 'Data Visualization   Data analysis',\n",
    " 'Statistical modeling',\n",
    " 'Machine learning',\n",
    " 'Supervised learning',\n",
    "'Econometrics and Time Series Analysis', \n",
    "    'Design of Experiments', 'Linear Models', 'Large Sample Theory',\n",
    "'Stochastic Process', 'Non-Parametric Methods',\n",
    "'Descision Theory', 'Data Mining', 'Statistical Inference', \n",
    "    'Probability Theory', 'Multivariate Statistical Modelling', 'Biostatistics',\n",
    "'Business Statistics','Machine Learning','Computer Vision',\n",
    "    'MS Excel', 'Power Point', 'Power BI','R','SAS','SQL','Excel','Machine Learning','Data Science']\n",
    "\n",
    "l = [item.lower() for item in l1]\n",
    "\n",
    "str2=str1.lower()\n",
    "skills=set(re.findall(r\"(?=(\"+'|'.join(l)+r\"))\",str2))\n",
    "\n",
    "mydict=dict()\n",
    "mydict['skills']=skills\n",
    "Data=pd.DataFrame({'Name':name,'Phone':phone,'E-mail':email,'Skills':mydict.values()})\n",
    "\n",
    "l2=['BE','B.Sc','B.Tech','Honours in Statistics']\n",
    "l3=['Masters in Statistics and Computing','m.tech','m.sc','M.Sc']\n",
    "\n",
    "Bachelors=set(re.findall(r\"(?=(\"+'|'.join(l2)+r\"))\",str1))\n",
    "if (len(Bachelors)!=0):\n",
    "    Data['Bachelors']=list(Bachelors)[0]\n",
    "else:\n",
    "    Data['Bachelors']=0\n",
    "    \n",
    "Masters=set(re.findall(r\"(?=(\"+'|'.join(l3)+r\"))\",str1))\n",
    "if (len(Masters)!=0):\n",
    "    Data['Masters']=list(Masters)[0]\n",
    "else:\n",
    "    Data['Masters']=0\n",
    "    \n",
    "\n",
    "headers=['summary','synopsis','academics','education','skills','skills summary','professional summary','academic projects','projects','experience','responsibilities','certifications']\n",
    "header_upper = [item.upper() for item in headers]\n",
    "header_title = [item.title() for item in headers]\n",
    "#print(header_upper)\n",
    "header_Proj_upper=list(re.findall(r\"(?=(\"+'|'.join(header_upper)+r\"))\",str1))\n",
    "header_Proj_title=list(re.findall(r\"(?=(\"+'|'.join(header_title)+r\"))\",str1))\n",
    "FInal_headers=[]\n",
    "if len(header_Proj_title)>len(header_Proj_upper):\n",
    "    Final_headers=header_Proj_title\n",
    "else:\n",
    "    Final_headers=header_Proj_upper\n",
    "#print(list(set(Final_headers)))\n",
    "\n",
    "\n",
    "a,b=str1.find('PROJECT'),str1.find('\\n')\n",
    "a1=str1[a:b]\n",
    "c,d=str1.find('EXPERIENCE'),str1.find('\\n')\n",
    "a2=str1[c:d]\n",
    "e,f=str1.find('Project'),str1.find('\\n')\n",
    "a3=str1[e:f]\n",
    "g,h=str1.find('Experience'),str1.find('\\n')\n",
    "a4=str1[g:h]\n",
    "\n",
    "m1=len(a1)\n",
    "m2=len(a2)\n",
    "m3=len(a3)\n",
    "m4=len(a4)\n",
    "\n",
    "\n",
    "if ((m1>m2) & (m1>m3) & (m1>m4)):\n",
    "    Data['Projects']=a1\n",
    "elif ((m2>m1) & (m2>m3) & (m2>m4)):\n",
    "    Data['Projects']=a2\n",
    "elif ((m3>m1) & (m3>m2) & (m3>m4)):\n",
    "    Data['Projects']=a3\n",
    "else:\n",
    "    Data['Projects']=a4\n",
    "    \n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ({excel, random forest, logistic regression, r...\n",
       "Name: Skills, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_excel('C:/Users/ashok.s/Downloads/demo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one= [i for i in Final_headers if re.search(r'PROJECT', i) ]\n",
    "print(len(one))\n",
    "#x1,y1=str1.find(one),str1.find('\\n')\n",
    "#z1=str1[x1:y1]\n",
    "\n",
    "two= [i for i in Final_headers if re.search(r'Project', i) ]\n",
    "print(len(two))\n",
    "#x2,y2=str1.find(two),str1.find('\\n')\n",
    "#z2=str1[x2:y2]\n",
    "\n",
    "three= [i for i in Final_headers if re.search(r'EXPERIENCE', i) ]\n",
    "print(len(three))\n",
    "#x3,y3=str1.find(three),str1.find('\\n')\n",
    "#z3=str1[x3:y3]\n",
    "\n",
    "four= [i for i in Final_headers if re.search(r'Experience', i) ]\n",
    "print(len(four))\n",
    "#x4,y4=str1.find(four),str1.find('\\n')\n",
    "#z4=str1[x4:y4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/ashok.s/Downloads/Simranjeet Singh CV.docx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "MY_TEXT = docx2txt.process(path)\n",
    "str1=MY_TEXT\n",
    "str1= str1.replace(' ', ' ').replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "\n",
    "def phone(str1):\n",
    "    if re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{12}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{12}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{10}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE)\n",
    "    \n",
    "def extract_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(string)\n",
    "\n",
    "import os\n",
    "base=os.path.basename(path)    \n",
    "name=base.split('_')[0]\n",
    "\n",
    "phone=phone(str1)\n",
    "\n",
    "email=extract_email_addresses(str1)\n",
    "\n",
    "l1=['PCA',\n",
    " 'dimension reduction',\n",
    " 'machine',\n",
    " 'Python',\n",
    " 'PCA',\n",
    " 'Logistic Regression',\n",
    " 'Decision Tree',\n",
    " 'Random Forest',\n",
    " 'NaÃ¯ve Baye',\n",
    " 'Regression testing',\n",
    " 'analysis /  reporting',\n",
    " 'sql',\n",
    " 'statistics',\n",
    " 'EDA',\n",
    " 'Tableau',\n",
    " 'Data cleaning',\n",
    " 'Data Visualization   Data analysis',\n",
    " 'Statistical modeling',\n",
    " 'Machine learning',\n",
    " 'Supervised learning',\n",
    "'Econometrics and Time Series Analysis', \n",
    "    'Design of Experiments', 'Linear Models', 'Large Sample Theory',\n",
    "'Stochastic Process', 'Non-Parametric Methods',\n",
    "'Descision Theory', 'Data Mining', 'Statistical Inference', \n",
    "    'Probability Theory', 'Multivariate Statistical Modelling', 'Biostatistics',\n",
    "'Business Statistics','Machine Learning','Computer Vision',\n",
    "    'MS Excel', 'Power Point', 'Power BI','R','SAS','SQL','Excel','Machine Learning','Data Science']\n",
    "\n",
    "l = [item.lower() for item in l1]\n",
    "\n",
    "str2=str1.lower()\n",
    "skills=set(re.findall(r\"(?=(\"+'|'.join(l)+r\"))\",str2))\n",
    "\n",
    "mydict=dict()\n",
    "mydict['skills']=skills\n",
    "Data=pd.DataFrame({'Name':name,'Phone':phone,'E-mail':email,'Skills':mydict.values()})\n",
    "\n",
    "l2=['BE','B.Sc','B.Tech','Honours in Statistics','B.COM','b.com']\n",
    "l3=['Masters in Statistics and Computing','m.tech','m.sc','M.Sc']\n",
    "\n",
    "Bachelors=set(re.findall(r\"(?=(\"+'|'.join(l2)+r\"))\",str2))\n",
    "if (len(Bachelors)!=0):\n",
    "    Data['Bachelors']=list(Bachelors)[0]\n",
    "else:\n",
    "    Data['Bachelors']=0\n",
    "    \n",
    "Masters=set(re.findall(r\"(?=(\"+'|'.join(l3)+r\"))\",str1))\n",
    "if (len(Masters)!=0):\n",
    "    Data['Masters']=list(Masters)[0]\n",
    "else:\n",
    "    Data['Masters']=0\n",
    "    \n",
    "\n",
    "headers=['summary','synopsis','academics','education','skills','skills summary','professional summary','academic projects','projects','experience','responsibilities','certifications']\n",
    "header_upper = [item.upper() for item in headers]\n",
    "header_title = [item.title() for item in headers]\n",
    "#print(header_upper)\n",
    "header_Proj_upper=list(re.findall(r\"(?=(\"+'|'.join(header_upper)+r\"))\",str1))\n",
    "header_Proj_title=list(re.findall(r\"(?=(\"+'|'.join(header_title)+r\"))\",str1))\n",
    "FInal_headers=[]\n",
    "if len(header_Proj_title)>len(header_Proj_upper):\n",
    "    Final_headers=header_Proj_title\n",
    "else:\n",
    "    Final_headers=header_Proj_upper\n",
    "#print(list(set(Final_headers)))\n",
    "\n",
    "\n",
    "a,b=str1.find('PROJECT'),str1.find('\\n')\n",
    "a1=str1[a:b]\n",
    "c,d=str1.find('EXPERIENCE'),str1.find('\\n')\n",
    "a2=str1[c:d]\n",
    "e,f=str1.find('Project'),str1.find('\\n')\n",
    "a3=str1[e:f]\n",
    "g,h=str1.find('Experience'),str1.find('\\n')\n",
    "a4=str1[g:h]\n",
    "\n",
    "m1=len(a1)\n",
    "m2=len(a2)\n",
    "m3=len(a3)\n",
    "m4=len(a4)\n",
    "\n",
    "\n",
    "if ((m1>m2) & (m1>m3) & (m1>m4)):\n",
    "    Data['Projects']=a1\n",
    "elif ((m2>m1) & (m2>m3) & (m2>m4)):\n",
    "    Data['Projects']=a2\n",
    "elif ((m3>m1) & (m3>m2) & (m3>m4)):\n",
    "    Data['Projects']=a3\n",
    "else:\n",
    "    Data['Projects']=a4\n",
    "    \n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd=r'C:\\Users\\ashok.s\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('C:/Users/ashok.s/Downloads/Simranjeet Singh CV-1.jpg')\n",
    "str1=pytesseract.image_to_string(img)\n",
    "\n",
    "img=cv2.imread('C:/Users/ashok.s/Downloads/Simranjeet Singh CV-2.jpg')\n",
    "strr=pytesseract.image_to_string(img)\n",
    "strr\n",
    "\n",
    "str1=str1+strr\n",
    "\n",
    "str1= str1.replace(' ', ' ').replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "\n",
    "def phone(str1):\n",
    "    if re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}\\s\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{5}-\\d{5}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}\\s\\d{3}\\s\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{3}-\\d{3}-\\d{4}',str1,re.IGNORECASE)\n",
    "    elif re.findall(r'\\d{12}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{12}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d{10}',str1,re.IGNORECASE) \n",
    "    elif re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE):\n",
    "        return re.findall(r'\\d\\d\\s\\d{10}',str1,re.IGNORECASE)\n",
    "    \n",
    "def extract_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(string)\n",
    "\n",
    "import os\n",
    "base=os.path.basename(path)    \n",
    "name=base.split('_')[0]\n",
    "\n",
    "phone=phone(str1)\n",
    "\n",
    "email=extract_email_addresses(str1)\n",
    "\n",
    "l1=['PCA',\n",
    " 'dimension reduction',\n",
    " 'machine',\n",
    " 'Python',\n",
    " 'PCA',\n",
    " 'Logistic Regression',\n",
    " 'Decision Tree',\n",
    " 'Random Forest',\n",
    " 'NaÃ¯ve Baye',\n",
    " 'Regression testing',\n",
    " 'analysis /  reporting',\n",
    " 'sql',\n",
    " 'statistics',\n",
    " 'EDA',\n",
    " 'Tableau',\n",
    " 'Data cleaning',\n",
    " 'Data Visualization   Data analysis',\n",
    " 'Statistical modeling',\n",
    " 'Machine learning',\n",
    " 'Supervised learning',\n",
    "'Econometrics and Time Series Analysis', \n",
    "    'Design of Experiments', 'Linear Models', 'Large Sample Theory',\n",
    "'Stochastic Process', 'Non-Parametric Methods',\n",
    "'Descision Theory', 'Data Mining', 'Statistical Inference', \n",
    "    'Probability Theory', 'Multivariate Statistical Modelling', 'Biostatistics',\n",
    "'Business Statistics','Machine Learning','Computer Vision',\n",
    "    'MS Excel', 'Power Point', 'Power BI','R','SAS','SQL','Excel','Machine Learning','Data Science']\n",
    "\n",
    "l = [item.lower() for item in l1]\n",
    "\n",
    "str2=str1.lower()\n",
    "skills=set(re.findall(r\"(?=(\"+'|'.join(l)+r\"))\",str2))\n",
    "\n",
    "mydict=dict()\n",
    "mydict['skills']=skills\n",
    "Data=pd.DataFrame({'Name':name,'Phone':phone,'E-mail':email,'Skills':mydict.values()})\n",
    "\n",
    "l2=['BE','B.Sc','B.Tech','Honours in Statistics','B.COM','b.com']\n",
    "l3=['Masters in Statistics and Computing','m.tech','m.sc','M.Sc']\n",
    "\n",
    "Bachelors=set(re.findall(r\"(?=(\"+'|'.join(l2)+r\"))\",str2))\n",
    "if (len(Bachelors)!=0):\n",
    "    Data['Bachelors']=list(Bachelors)[0]\n",
    "else:\n",
    "    Data['Bachelors']=0\n",
    "    \n",
    "Masters=set(re.findall(r\"(?=(\"+'|'.join(l3)+r\"))\",str1))\n",
    "if (len(Masters)!=0):\n",
    "    Data['Masters']=list(Masters)[0]\n",
    "else:\n",
    "    Data['Masters']=0\n",
    "    \n",
    "headers=['summary','synopsis','academics','education','skills','skills summary','professional summary','academic projects','projects','experience','responsibilities','certifications']\n",
    "header_upper = [item.upper() for item in headers]\n",
    "header_title = [item.title() for item in headers]\n",
    "#print(header_upper)\n",
    "header_Proj_upper=list(re.findall(r\"(?=(\"+'|'.join(header_upper)+r\"))\",str1))\n",
    "header_Proj_title=list(re.findall(r\"(?=(\"+'|'.join(header_title)+r\"))\",str1))\n",
    "FInal_headers=[]\n",
    "if len(header_Proj_title)>len(header_Proj_upper):\n",
    "    Final_headers=header_Proj_title\n",
    "else:\n",
    "    Final_headers=header_Proj_upper\n",
    "#print(list(set(Final_headers)))\n",
    "\n",
    "\n",
    "a,b=str1.find('PROJECT'),str1.find('\\n')\n",
    "a1=str1[a:b]\n",
    "c,d=str1.find('EXPERIENCE'),str1.find('\\n')\n",
    "a2=str1[c:d]\n",
    "e,f=str1.find('Project'),str1.find('\\n')\n",
    "a3=str1[e:f]\n",
    "g,h=str1.find('Experience'),str1.find('\\n')\n",
    "a4=str1[g:h]\n",
    "\n",
    "m1=len(a1)\n",
    "m2=len(a2)\n",
    "m3=len(a3)\n",
    "m4=len(a4)\n",
    "\n",
    "\n",
    "if ((m1>m2) & (m1>m3) & (m1>m4)):\n",
    "    Data['Projects']=a1\n",
    "elif ((m2>m1) & (m2>m3) & (m2>m4)):\n",
    "    Data['Projects']=a2\n",
    "elif ((m3>m1) & (m3>m2) & (m3>m4)):\n",
    "    Data['Projects']=a3\n",
    "else:\n",
    "    Data['Projects']=a4\n",
    "    \n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(str1):\n",
    "    if re.findall(r'[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s\\d{4}[)]',str1,re.IGNORECASE):\n",
    "        return re.findall(r'[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s\\d{4}[)]',str1,re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'       PROFILE   CORE   COMPETENCIES   APERCU   PROFESSIONAL  EXPERIENCE       Joydeep Sen     Cell: +91-9674995622, Email: joydeepeco2012@gmail.com      A professional with having 6 years of experience in analytical projects who believes in no-holds barred hard  work.  Expertise  in  SAS/Base,  SAS/SQL,  SAS/MACRO,  SQL,  R  Studio,  Python  &  Tableau.  Passionate  about  solving complex business problems using predictive modelling.     \\uf0c4  Project Leadership  \\uf0c4  Client relations  \\uf0c4  Process Improvements      \\uf0c4  Regression Analysis   Multiple Linear Regression Model ,  Logistic Regression,  Mix modelling,   \\uf0c4  Machine Learning Techniques Decision Trees, Random Forest   HDFC Life , Bangalore, India (Designation â Senior Modeler)  (Sept 2018 â Dec 2018)  Environment:  SAS Enterprise Guide, R Studio    Objective: Built Agent Inactivation model using logistic regression model.   \\uf0b7  Agency is one popular channel to source our policyholders. Agents are people who sell the policies   \\uf0b7   \\uf0b7   \\uf0b7   & earn commissions & incentives.   They are mapped to FLS (front line sales), our in house sales person. Agent donât leave (do not need  to as they are not our payroll) but they can get inactive (that is earning not even one policy in past  12 months).   Factor driving agent productivity & inactivity can be many including  their overall experience, past  commission earning patterns( velocity in 3 months, 6 months, ratio of velocity etc.), type of location  they  are  based  out  of(metro,  tier1  or  tier2  cities),  the  performance  metric  of  the  FLS  they  are  mapped.   Thus the model should be predicting that given the profile and performance of an agent, what is the  probability that the agent will not sell even one policy in next 12 months.    IPSOS Research Pvt limited , Bangalore, India (Designation â Consultant)  (June 2016 â July 2018)    Market Mix Modeling: Hands on model building and estimating the response impact of different promotion  and media activities done by clients on the performance of clientâs products sale. An individual contributor  as well as proactive team player.  Data Validation, Data analysis: ensuring reasonableness of data.  Primary  model  development:  working  to  build  regression  models,  understanding  model  accuracy  &  interacting with client servicing team at regular intervals to validate & discuss the models developed, data  handling in excel & SAS.  ROI/MROI creation: to reason out the return on investment from the incremental tactics & the saturation  levels in investment.    Tata Consultancy Services â Analytics and Insights, India (Designation â Business Analyst)  (August 2012 â May 2016)  Key Projects    Project 3:   Environment:  SAS Enterprise Guide 4.1                                  Role:                 Analyst                        \\x0c               Business objective:   Building up logistic regression model to predict the delinquency.    Responsibilities:    \\uf0b7   Collecting  data  from  different  data  source,  Data  cleaning,  multicollinearity  check,  finally  validation of the model and finally helping the client to formulate business strategy.  Creating Reconciliation Summary Report (Current & Origination).  Preparing Trend Analysis for different portfolio.(Data size:3.5 million)  Preparing Trend Analysis Report using graphs(used advanced excel)  Preparing Swap set analysis for Current & Origination.   \\uf0b7  \\uf0b7  \\uf0b7  \\uf0b7  \\uf0b7  DATA  Step  programming  and  SAS  procedures  like  PROC  SORT,  APPEND,  CONTENTS,  FREQ,   TRANSPOSE, MEANS, SUMMARY, TABULATE, REPORT, UNIVARIATE etc.   Process Improvement   \\uf0a7  Developed  SAS  Macro  where large  databases (7  yrsâ  historical  data)  needed  to be  extracted  at  a   time for further analysis      Project 2:   Environment:  R studio, SQL Server management studio 2012, Tableau desktop, Tableau Server                     Role:                 Analyst    Business objective:    Audit Analytics:   Data mainly consists of Travel & expense data for Time Warner Corp.  Time Warner employees have to travel  different countries for their business purposes. After completion of their travel they have to claim their  travel or expense amount for reimbursement. So they are giving the proper comment or not on the basis of  proper expense type that we have to check programmatically.  For example: Under miscellaneous expense type, they should not include lunch, meal, dinner, taxi expense &  airfare expense these types of words in comment section. So in audit prospective it should not be included in  miscellaneous type.    Responsibilities:    Created SQL View   Connected SQL View or table with R studio.  Created word cloud in R with the help of text mining package(TM) for TimeWarner.   \\uf0b7  \\uf0b7  \\uf0b7  \\uf0b7  Designed, developed & implemented Tableau Dashboard.  \\uf0b7  Responsible for dashboard design, look & feel & development.  \\uf0b7  Use parameters & input controls to give users control over certain values.  \\uf0b7  \\uf0b7  \\uf0b7   Combine data sources by joining multiple tables & using data blending.   Connected R with Tableau & run R script in Tableau environment with help of Rserve package.   Created Word Cloud in Tableau 9.0 .     Project 1:  Environment:   BASE SAS 9.3                                 Role:                  Analyst    Responsibilities:    \\uf0b7  Broad review of all available data by checking and treating on Missing values and Outliers and make   them Usable Sample.            \\x0c          \\uf0b7  Major  clients  include  P&G,  Unilever,  Coke  and  Pepsi  who  wants  to  know  their  current  market  scenario in terms of their product sales. Their position with respect to their competitors and future  updates  how  the  market  will  behave  if  any  new  product  is  launched.  Also  how  a  placement  of  product in a supermarket can help increase their sales etc.   Trend analysis of retail sales data, outlier detection, missing value check & Regression modeling   Identify the channels and markets that represent brandâs growth potential   \\uf0b7  \\uf0b7  \\uf0b7  Analysis & preparing reports on product movement, market share, numeric & weighted distribution   and price across retails channels, defined markets    Client Query:   \\uf0b7   Handling  end  client  inquiries  &  ad-hoc  requests  that  involves  analyzing  data  and  suggesting  insights from data. Manipulating and extracting data from the data base using SAS codes.       SOFTWARES  \\uf0c4  Statistical Tool   SAS (SAS/Base, SAS/Macros, SAS/STAT, SAS/SQL), R-Studio, Python.   \\uf0c4  Database & Business Objects   SQL server management studio 2012  \\uf0c4  Documentation   MS-Office  \\uf0c4  Data Visualization Tableau    ACADEMICS  \\uf0c4  M.Sc. in Economics from Department of Economics, University of Calcutta, Kolkata, India. (2012)    B.Sc. in Economics from Asutosh College, Kolkata. (2010)      \\uf0c4         I hereby declare that all information provided here are true to best of my knowledge and belief.  Date: September 26, 2019.            (Joydeep Sen)                                   \\x0c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Sept 2018 â Dec 2018)',\n",
       " '(June 2016 â July 2018)',\n",
       " '(August 2012 â May 2016)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa=date(str1)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Sept 2018 â Dec 2018)',\n",
       " '(June 2016 â July 2018)',\n",
       " '(August 2012 â May 2016)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HDFC Life , Bangalore, India (Designation â Senior Modeler)  (Sept 2018 â Dec 2018)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = re.search(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,7}[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s\\d{4}[)](?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,0}\", str1)\n",
    "r1.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sept 2018 â Dec 2018),(June 2016 â July 2018),(August 2012 â May 2016)\n",
      "HDFC Life , Bangalore, India (Designation â Senior Modeler)  (Sept 2018 â Dec 2018\n"
     ]
    }
   ],
   "source": [
    "b=[]\n",
    "for i in aaa:\n",
    "    b.append(i)\n",
    "ccc=(','.join(b))\n",
    "print(ccc)\n",
    "\n",
    "r1 = re.search(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,7}\"+b[0]+\"(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,0}\", str1)\n",
    "print(r1.group())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Forest   HDFC Life , Bangalore, India (Designation â Senior Modeler)  (Sept 2018 â Dec 2018', 'IPSOS Research Pvt limited , Bangalore, India (Designation â Consultant)  (June 2016 â July 2018', 'Services â Analytics and Insights, India (Designation â Business Analyst)  (August 2012 â May 2016']\n"
     ]
    }
   ],
   "source": [
    "dd=[]\n",
    "for i in aaa:\n",
    "    #print(''.join(i))\n",
    "    r1 = re.search(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,8}\"+i+\"(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,0}\", str1)\n",
    "    dd.append(r1.group())\n",
    "print(dd)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forest   HDFC Life , Bangalore, India (Designation â Senior Modeler)  (Sept 2018 â Dec 2018',\n",
       " 'IPSOS Research Pvt limited , Bangalore, India (Designation â Consultant)  (June 2016 â July 2018',\n",
       " 'Services â Analytics and Insights, India (Designation â Business Analyst)  (August 2012 â May 2016']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Sept 2018 â Dec 2018)',\n",
       " '(June 2016 â July 2018)',\n",
       " '(August 2012 â May 2016)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sept 2018\n",
      "Dec 2018\n"
     ]
    }
   ],
   "source": [
    "b=aaa[0]\n",
    "c=b.split('â')\n",
    "c[0]=c[0].strip()\n",
    "c[0]=c[0].replace('(','')\n",
    "c[0]=c[0].replace(')','')\n",
    "c[0]=c[0].split('â')\n",
    "c[0]\n",
    "dc=[]\n",
    "for i in c[0]:\n",
    "    print(i.strip())\n",
    "    dc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.033333333333333\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "dt = parse(dc[0])\n",
    "# datetime.datetime(2010, 2, 15, 0, 0)\n",
    "dt=dt.strftime('%m/%Y')\n",
    "\n",
    "\n",
    "dtt = parse(dc[1])\n",
    "# datetime.datetime(2010, 2, 15, 0, 0)\n",
    "dtt=dtt.strftime('%m/%Y')\n",
    "#curr date\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "date_format = \"%m/%Y\"\n",
    "a = datetime.strptime(dt, date_format)\n",
    "b = datetime.strptime(dtt, date_format)\n",
    "delta = b - a\n",
    "print((delta.days)/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.166666666666667\n"
     ]
    }
   ],
   "source": [
    "tot=[]\n",
    "for i in aaa:\n",
    "    b=i\n",
    "    c=b.split('â')\n",
    "    c[0]=c[0].strip()\n",
    "    c[0]=c[0].replace('(','')\n",
    "    c[0]=c[0].replace(')','')\n",
    "    c[0]=c[0].split('â')\n",
    "    c[0]\n",
    "    dc=[]\n",
    "    for i in c[0]:\n",
    "        #print(i.strip())\n",
    "        dc.append(i)\n",
    "#from dateutil.parser import parse\n",
    "    dt = parse(dc[0])\n",
    "# datetime.datetime(2010, 2, 15, 0, 0)\n",
    "    dt=dt.strftime('%m/%Y')\n",
    "\n",
    "\n",
    "    dtt = parse(dc[1])\n",
    "# datetime.datetime(2010, 2, 15, 0, 0)\n",
    "    dtt=dtt.strftime('%m/%Y')\n",
    "#curr date\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "\n",
    "    date_format = \"%m/%Y\"\n",
    "    a = datetime.strptime(dt, date_format)\n",
    "    b = datetime.strptime(dtt, date_format)\n",
    "    delta = b - a\n",
    "    #print((delta.days)/30)\n",
    "    tot.append((delta.days)/30)\n",
    "print(sum(tot)/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = re.search(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,0}Experience(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,200}\", str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=r1.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\w+[' ']\\d+[-][A-Z]+',r1.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile('[a-zA-Z]+\\s+\\d{4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(str1):\n",
    "    if re.findall(r'[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s[A-Za-z]+[)]',str1,re.IGNORECASE):\n",
    "        return re.findall(r'[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s[A-Za-z]+[)]',str1,re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=date(ss)\n",
    "exp\n",
    "a=[]\n",
    "for i in exp:\n",
    "    a.append(i)\n",
    "b=a[0]\n",
    "c=b.split('â')\n",
    "c[0]=c[0].strip()\n",
    "c[0]=c[0].replace('(','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = re.search(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,5}[(][a-zA-Z]+\\s+\\d{4}\\s[â]\\s[A-Za-z]+\\s[A-Za-z]+[)](?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,0}\", str1)\n",
    "r1.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "dt = parse(c[0])\n",
    "# datetime.datetime(2010, 2, 15, 0, 0)\n",
    "dt=dt.strftime('%m/%Y')\n",
    "#curr date\n",
    "d1 = today.strftime(\"%m/%Y\")\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "date_format = \"%m/%Y\"\n",
    "a = datetime.strptime(dt, date_format)\n",
    "b = datetime.strptime(d1, date_format)\n",
    "delta = b - a\n",
    "print((delta.days)/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%m/%Y\")\n",
    "print(\"d1 =\", d1)\n",
    "# Textual month, day and year\t\n",
    "d2 = today.strftime(\"%B %d, %Y\")\n",
    "print(\"d2 =\", d2)\n",
    "# mm/dd/y\n",
    "d3 = today.strftime(\"%m/%d/%y\")\n",
    "print(\"d3 =\", d3)\n",
    "# Month abbreviation, day and year\t\n",
    "d4 = today.strftime(\"%b-%d-%Y\")\n",
    "print(\"d4 =\", d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
